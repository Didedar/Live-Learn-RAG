# Live-Learn RAG System with Gemini AI

Enhanced Retrieval-Augmented Generation (RAG) system with Google Gemini AI and user feedback learning capabilities.

## üöÄ Quick Start

### 1. Prerequisites

- Python 3.8+
- Google AI API key ([–ø–æ–ª—É—á–∏—Ç—å –∑–¥–µ—Å—å](https://aistudio.google.com/app/apikey))

### 2. Installation

```bash
# –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
git clone <repository-url>
cd rag-system

# –°–æ–∑–¥–∞–µ–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements.txt
```

### 3. Configuration

```bash
# –ö–æ–ø–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
cp .env.example .env

# –†–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º .env —Ñ–∞–π–ª –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤–∞—à Google AI API key
# GOOGLE_API_KEY=your_actual_google_api_key_here
```

### 4. Run the Server

```bash
# –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º Python –Ω–∞–ø—Ä—è–º—É—é
python -m uvicorn app.main:app --reload
```

### 5. Test the System

```bash
# –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç
python test_rag_system.py
```

## üìã API Endpoints

### Health Check
```http
GET /healthz
GET /healthz/detailed
```

### RAG Operations
```http
# Ask a question
POST /api/v1/feedback/ask
Content-Type: application/json

{
    "question": "What is artificial intelligence?",
    "session_id": "optional-session-id",
    "top_k": 6
}

# Ingest a document
POST /api/v1/ingest
Content-Type: application/json

{
    "text": "Your document content here...",
    "metadata": {"title": "Document Title", "source": "web"}
}

# Upload a file
POST /api/v1/ingest
Content-Type: multipart/form-data

file: your_document.txt
```

### Feedback System
```http
# Submit feedback
POST /api/v1/feedback/feedback
Content-Type: application/json

{
    "message_id": "message-id-from-ask-response",
    "question": "Original question",
    "model_answer": "Model's answer",
    "user_feedback": {
        "label": "incorrect",
        "correction_text": "The correct answer is...",
        "scope": "chunk",
        "reason": "The information is outdated"
    }
}
```

## üèóÔ∏è Architecture

```
app/
‚îú‚îÄ‚îÄ main.py              # FastAPI application entry point
‚îú‚îÄ‚îÄ config.py            # Configuration management
‚îú‚îÄ‚îÄ database.py          # Database setup and connections
‚îú‚îÄ‚îÄ api/v1/              # API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ feedback.py      # Feedback and ask endpoints
‚îÇ   ‚îî‚îÄ‚îÄ rag.py          # Document ingestion and retrieval
‚îú‚îÄ‚îÄ models/              # Database models
‚îÇ   ‚îú‚îÄ‚îÄ documents.py     # Document and chunk models
‚îÇ   ‚îî‚îÄ‚îÄ feedback.py      # Feedback system models
‚îú‚îÄ‚îÄ schemas/             # Pydantic schemas
‚îÇ   ‚îú‚îÄ‚îÄ feedback.py      # Feedback API schemas
‚îÇ   ‚îî‚îÄ‚îÄ rag.py          # RAG API schemas  
‚îú‚îÄ‚îÄ services/            # Business logic
‚îÇ   ‚îú‚îÄ‚îÄ embeddings.py    # Google AI & OpenAI embeddings
‚îÇ   ‚îú‚îÄ‚îÄ llm.py          # Gemini LLM integration
‚îÇ   ‚îú‚îÄ‚îÄ rag_pipeline.py  # Main RAG pipeline
‚îÇ   ‚îî‚îÄ‚îÄ feedback_handler.py # Feedback processing
‚îú‚îÄ‚îÄ utils/               # Utility functions
‚îÇ   ‚îú‚îÄ‚îÄ text_processing.py # Text chunking and processing
‚îÇ   ‚îî‚îÄ‚îÄ vectors.py       # Vector operations
‚îî‚îÄ‚îÄ core/               # Core functionality
    ‚îî‚îÄ‚îÄ exceptions.py   # Custom exceptions
```

## üß™ Testing

### Automated Tests
```bash
# –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤
python test_rag_system.py

# –¢–µ—Å—Ç —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (–±–µ–∑ —Å–µ—Ä–≤–µ—Ä–∞)
python -c "import asyncio; from test_rag_system import test_basic_functionality; asyncio.run(test_basic_functionality())"
```

### Manual Testing

1. **Health Check**: `curl http://localhost:8000/healthz`
2. **Ask Question**: 
   ```bash
   curl -X POST "http://localhost:8000/api/v1/feedback/ask" \
        -H "Content-Type: application/json" \
        -d '{"question": "What is AI?", "session_id": "test"}'
   ```
3. **Ingest Document**:
   ```bash
   curl -X POST "http://localhost:8000/api/v1/ingest" \
        -H "Content-Type: application/json" \
        -d '{"text": "AI is artificial intelligence..."}'
   ```

## üîß Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `GOOGLE_API_KEY` | Google AI API key | Required |
| `LLM_MODEL` | Gemini model name | `gemini-2.0-flash-exp` |
| `EMBEDDING_MODEL` | Embedding model | `text-embedding-004` |
| `CHUNK_SIZE` | Text chunk size in tokens | `400` |
| `CHUNK_OVERLAP` | Overlap between chunks | `40` |
| `DEFAULT_TOP_K` | Default retrieval count | `6` |
| `DEBUG` | Debug mode | `false` |

### Google AI Setup

1. Go to [Google AI Studio](https://aistudio.google.com/app/apikey)
2. Create a new API key
3. Add it to your `.env` file as `GOOGLE_API_KEY`

## üêõ Troubleshooting

### Common Issues

1. **"Ask pipeline failed" error**:
   - Check if `GOOGLE_API_KEY` is set correctly
   - Verify the API key has proper permissions
   - Check logs for detailed error messages

2. **Import errors**:
   - Ensure all dependencies are installed: `pip install -r requirements.txt`
   - Check Python version (3.8+ required)

3. **Database issues**:
   - Delete `rag.db` to reset the database
   - Check file permissions in the project directory

4. **Empty responses**:
   - First ingest some documents using `/api/v1/ingest`
   - Check if documents are properly chunked and embedded

### Debug Mode

Set `DEBUG=true` in `.env` for detailed error messages and logs.

### Logs

Check the console output for detailed logs using Loguru formatting.

## üìñ Usage Examples

### 1. Basic Q&A

```python
import httpx
import asyncio

async def ask_question():
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/api/v1/feedback/ask",
            json={
                "question": "What is machine learning?",
                "session_id": "demo-session",
                "top_k": 5
            }
        )
        return response.json()

result = asyncio.run(ask_question())
print(result['answer'])
```

### 2. Document Ingestion

```python
import httpx
import asyncio

async def ingest_document():
    document_text = """
    Machine Learning is a subset of artificial intelligence that provides 
    systems the ability to automatically learn and improve from experience 
    without being explicitly programmed.
    """
    
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/api/v1/ingest",
            json={
                "text": document_text,
                "metadata": {"title": "ML Introduction", "source": "manual"}
            }
        )
        return response.json()

result = asyncio.run(ingest_document())
print(f"Document {result['document_id']} ingested with {result['chunks']} chunks")
```

### 3. Feedback Submission

```python
import httpx
import asyncio

async def submit_feedback(message_id):
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/api/v1/feedback/feedback",
            json={
                "message_id": message_id,
                "question": "What is machine learning?",
                "model_answer": "Previous answer from the model",
                "user_feedback": {
                    "label": "partially_correct",
                    "correction_text": "Also mention deep learning as a subset",
                    "scope": "chunk",
                    "reason": "Missing important information"
                }
            }
        )
        return response.json()

# Use message_id from ask response
result = asyncio.run(submit_feedback("your-message-id-here"))
print(f"Feedback processed: {result['status']}")
```

## üîÑ Development

### Code Structure

- **Services**: Core business logic (embeddings, LLM, pipeline)
- **Models**: SQLAlchemy database models
- **Schemas**: Pydantic input/output validation
- **API**: FastAPI route handlers
- **Utils**: Helper functions for text processing and vectors

### Adding New Features

1. Add models in `models/`
2. Create schemas in `schemas/`
3. Implement business logic in `services/`
4. Add API endpoints in `api/v1/`
5. Update tests in `test_rag_system.py`

## üìÑ License

This project is licensed under the MIT License.

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make changes and add tests
4. Submit a pull request

## üìû Support

If you encounter issues:

1. Check the troubleshooting section above
2. Run the test script: `python test_rag_system.py`
3. Enable debug mode in `.env`
4. Check the logs for detailed error messages